{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(5000):\\n    print(i, Counter(X[:, i]))'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X = pickle.load(open('train_data.pkl', 'rb')).todense()  # unsupported in Python 2\n",
    "y = pickle.load(open('train_targets.pkl', 'rb'))\n",
    "Xt = pickle.load(open('test_data.pkl', 'rb')).todense()\n",
    "\n",
    "\"\"\"print(type(X))\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(Xt.shape)\"\"\"\n",
    "\n",
    "# convert data from np.matrix to np.ndarray\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "Xt = np.asarray(Xt)\n",
    "\"\"\"for i in range(5000):\n",
    "    print(i, Counter(X[:, i]))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_DISCRETE = 2500\n",
    "N_DISCRETE_VALUES = 2\n",
    "LAPLACE_CORRECTION_ALPHA = 1.  # laplace correction coefficient!\n",
    "STD_RATIO = 1e-4  # deal with zero std!\n",
    "\n",
    "\n",
    "def log_norm_pdf_vectorize(x_arr, means, stds):\n",
    "    assert len(x_arr) == len(means) and len(x_arr) == len(stds)\n",
    "    return (- np.power(x_arr - means, 2) / (2 * np.power(stds, 2))\n",
    "            - math.log(2 * math.pi) / 2\n",
    "            - np.log(stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_naive_bayes(xtrain, ytrain):\n",
    "    n_total = xtrain.shape[0]\n",
    "    class_data = dict()\n",
    "    y_values = []\n",
    "\n",
    "    # store data from different classes in a dictionary\n",
    "    for c, n in Counter(ytrain).items():\n",
    "        y_values.append(c)\n",
    "        class_data[c] = {'n': n, 'index': (ytrain == c), 'prior': n / n_total, 'discrete_prob': None, 'pdf_arr': None}\n",
    "    class_data['y_values'] = y_values\n",
    "    class_data['n_total'] = n_total\n",
    "\n",
    "    for c in class_data['y_values']:\n",
    "        mask = class_data[c]['index']\n",
    "        n_samples = class_data[c]['n']\n",
    "\n",
    "        discrete_features, continuous_features = xtrain[mask, : N_DISCRETE], xtrain[mask, N_DISCRETE:]\n",
    "\n",
    "        # for each discrete feature, calculate P(x = 0 | y) and P(x = 1 | y)\n",
    "        class_data[c]['discrete_prob'] = np.empty((N_DISCRETE_VALUES, N_DISCRETE))\n",
    "        for i in range(N_DISCRETE_VALUES):\n",
    "            class_data[c]['discrete_prob'][i, :] = ((np.sum(discrete_features == i, axis=0) + LAPLACE_CORRECTION_ALPHA)\n",
    "                                                    / (n_samples + LAPLACE_CORRECTION_ALPHA * N_DISCRETE_VALUES))  # with lapace smoothing\n",
    "\n",
    "        # for each continuous feature, calculate mean and std\n",
    "        means, stds = continuous_features.mean(axis=0), continuous_features.std(axis=0)\n",
    "        stds += 1e-3\n",
    "        class_data[c]['means'], class_data[c]['stds'] = means, stds\n",
    "\n",
    "    return class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_posterior(x, oneclass_data):\n",
    "    \"\"\"return posterior probability of sample x.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    oneclass_data : dict. oneclass_data = class_data[c], with c from y_values\n",
    "    x : np.ndarray. 1D sample features.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    posterior : float.\n",
    "\n",
    "    \"\"\"\n",
    "    x_discrete, x_continuous = x[: N_DISCRETE].astype(int), x[N_DISCRETE:]  # convert to int, in order to be index. (2500,)\n",
    "\n",
    "    # calculate discrete likelihood\n",
    "    # oneclass_data['discrete_prob'].shape = (2, 2500)\n",
    "    probabilities_1 = oneclass_data['discrete_prob'][x_discrete, np.arange(N_DISCRETE)]  # advanced slicing! shape = (2500, )\n",
    "    log_likelihood_discrete = np.sum(np.log(probabilities_1))\n",
    "\n",
    "    # calculate continuous likelihood\n",
    "    probabilities_2 = log_norm_pdf_vectorize(x_continuous, oneclass_data['means'], oneclass_data['stds'])\n",
    "    log_likelihood_continuous = np.sum(probabilities_2)\n",
    "\n",
    "    # calculate P(y | x) = P(x | y) * P(y)\n",
    "    posterior = (math.log(oneclass_data['prior'])\n",
    "                 + log_likelihood_discrete\n",
    "                 + log_likelihood_continuous  # * 1e-5 # prevent this from being dominant\n",
    "                 )\n",
    "\n",
    "    return posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------------------------------------------------------------\n",
    "# training 0.061s. mine: 2.011\n",
    "\n",
    "class_data = train_naive_bayes(X, y)\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "# testing (predicting)\n",
    "\n",
    "# load test data, loop for each data for each class\n",
    "posterior_matrix = np.empty((Xt.shape[0], len(class_data['y_values'])))\n",
    "for i, x in enumerate(Xt):\n",
    "    for c in class_data['y_values']:\n",
    "        posterior_matrix[i, c] = calc_posterior(x, class_data[c])\n",
    "\n",
    "# compare and classify\n",
    "y_pred = np.argmax(posterior_matrix, axis=1).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction and output completed. \n",
      "Total time cost: 277.222 seconds.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------\n",
    "# save data\n",
    "np.savetxt('test_predictions.csv', y_pred, fmt='%s', delimiter=',', newline='\\n')\n",
    "\n",
    "time_cost = time.time() - start_time\n",
    "print(\"\\nPrediction and output completed. \\nTotal time cost: {:6.3f} seconds.\".format(time_cost))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test on data type\n",
    "x = X[0]\n",
    "x_discrete, x_continuous = x[: N_DISCRETE].astype(int), x[N_DISCRETE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneclass_data = class_data[0]  \n",
    "oneclass_data['discrete_prob'] # (2, 2500)\n",
    "oneclass_data['discrete_prob'][ [1, 0, 1, 0] ].shape # (4, 2500)\n",
    "oneclass_data['discrete_prob'][ [1, 0, 1, 0], 1] # (4, 1)\n",
    "oneclass_data['discrete_prob'][ [1, 0, 1, 0], [1, 0, 1, 0] ].shape # (4, )\n",
    "#probabilities_1 = oneclass_data['discrete_prob'][x_discrete, np.arange(N_DISCRETE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
