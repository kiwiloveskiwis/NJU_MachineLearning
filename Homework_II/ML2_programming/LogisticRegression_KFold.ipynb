{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import seterr\n",
    "from numpy import transpose as trans\n",
    "import sklearn, sys\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "np.seterr(over='raise', under='ignore', divide='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data.csv', delimiter = ',')\n",
    "data = sklearn.preprocessing.normalize(data)\n",
    "target = np.genfromtxt('targets.csv', delimiter = ',')\n",
    "data_hat = np.append(data, np.ones([data.shape[0], 1]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.92541486e-03,   4.57286305e-03,   5.40989964e-02, ...,\n",
       "          1.16920795e-04,   2.02695018e-04,   5.23808686e-05],\n",
       "       [  8.66575595e-03,   7.48616836e-03,   5.59882822e-02, ...,\n",
       "          7.83583182e-05,   1.15852352e-04,   3.75024596e-05],\n",
       "       [  9.36668268e-03,   1.01087865e-02,   6.18419883e-02, ...,\n",
       "          1.15596947e-04,   1.71873157e-04,   4.16624718e-05],\n",
       "       ..., \n",
       "       [  2.14019837e-02,   6.33224349e-02,   1.34594243e-01, ...,\n",
       "          0.00000000e+00,   5.62134241e-04,   1.58283375e-04],\n",
       "       [  1.46457050e-02,   2.27665929e-02,   9.67580197e-02, ...,\n",
       "          1.10921892e-04,   2.26662111e-04,   8.03455949e-05],\n",
       "       [  1.81413232e-02,   3.77169300e-02,   1.17453641e-01, ...,\n",
       "          1.52144390e-04,   3.32879884e-04,   1.37628179e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    max_elem = max(-x) \n",
    "#     print(max_elem)\n",
    "#     print(np.exp(0 - max_elem))\n",
    "#     print(np.exp(- x - max_elem))\n",
    "#     print(min(np.exp(0 - max_elem) + np.exp(- x - max_elem)))\n",
    "    try: \n",
    "        res = -(np.log(np.exp(0 - max_elem) + np.exp(- x - max_elem)) + max_elem ) # Only underflow could happen\n",
    "        res = np.exp(res)\n",
    "    except Exception as e:\n",
    "        res = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hypo(x_hat, beta):\n",
    "    return sigmoid(np.matmul(x_hat, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def cost(x_hat, beta, y):\n",
    "#    return sum(-np.log(y * np.exp(np.matmul(x_hat, beta)) + 1 - y) + np.log(1 + np.exp(hypo(x_hat, beta)))) \n",
    "    # -y*hypo(x_hat, beta) is element-wise\n",
    "def prob_eq_one(x_hat, beta):\n",
    "    max_elem = max(np.matmul(x_hat, beta))\n",
    "    try:\n",
    "        log =  np.matmul(x_hat, beta) - (np.log(np.exp(0 - max_elem) + np.exp(np.matmul(x_hat, beta) - max_elem)) + max_elem)\n",
    "        res = trans(np.exp(log))\n",
    "    except:\n",
    "        res =  trans(np.zeros([x_hat.shape[0]]))\n",
    "    # res_2 = np.exp(np.matmul(x_hat, beta)) / (1 + np.exp(np.matmul(x_hat, beta))) # Might Overflow\n",
    "    # print(res - res_2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(X, beta, y):\n",
    "    return np.count_nonzero(abs(np.round(hypo(X, beta)) - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad(x_hat, beta, y, speed=1):\n",
    "    p1 = prob_eq_one(x_hat, beta)\n",
    "    # print(1+np.exp(np.matmul(x_hat, beta)))\n",
    "    # print(np.exp(np.matmul(x_hat, beta)))\n",
    "    # print(np.exp(np.matmul(x_hat, beta)) / (1 + np.exp(np.matmul(x_hat, beta))))\n",
    "    ans = - np.matmul(trans(y) - p1,  x_hat)\n",
    "    return ans*speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hessian(x_hat, beta):\n",
    "    m, d = x_hat.shape[0], x_hat.shape[1]\n",
    "\n",
    "    p1 = prob_eq_one(x_hat, beta)\n",
    "    p1_mult = p1 * (1 - p1)\n",
    "    res = np.zeros([d, d])\n",
    "    for i in range(m):\n",
    "        #print(x_hat[i, :].size)\n",
    "        #print(trans(x_hat[i, :]).size)\n",
    "        #print(np.outer(x_hat[i, :], trans(x_hat[i, :])))\n",
    "        res += p1_mult[i] * np.outer(x_hat[i, :], x_hat[i, :])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_train(X, y, iter, beta):\n",
    "    for i in range(iter):\n",
    "        p1 = prob_eq_one(X, beta)\n",
    "        hess = hessian(X, beta)\n",
    "        beta_save = beta\n",
    "        try:\n",
    "            inv = np.linalg.inv(hess)\n",
    "            beta -= np.matmul(inv, grad(X, beta, y))\n",
    "        except Exception as e:\n",
    "            if(np.max(hess) < np.exp(-100)):\n",
    "                break\n",
    "            else:\n",
    "                beta = beta_save - grad(X, beta, y)\n",
    "    print(error(data_hat, beta, target))\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with K-Fold\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "3\n",
      "7\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for k, (train, test) in enumerate(kf.split(data, target)):\n",
    "    m = data_hat[test].shape[0]\n",
    "    beta = np.zeros(data_hat.shape[1], dtype=float)\n",
    "    \n",
    "    iter_beta = my_train(data_hat[train], target[train], 100,  beta)\n",
    "    \n",
    "    to_save = np.round(hypo(data_hat[test], iter_beta)).reshape(m, 1)\n",
    "    to_save = np.dstack((test + 1 , to_save[:,0]))[0]\n",
    "    np.savetxt('fold%d.csv'%(k+1), to_save, \"%d,%d\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.46562904e+05,  -2.88608022e+03,  -1.78849310e+03,\n",
       "        -5.07921662e+02,  -1.36886348e+06,   1.61563361e+06,\n",
       "        -7.61826065e+05,  -9.53858898e+05,   4.20942634e+05,\n",
       "        -1.34389190e+06,  -5.12949165e+04,   4.59332470e+03,\n",
       "         2.09013671e+04,  -2.14872872e+03,   2.54039706e+06,\n",
       "        -2.14127534e+06,   2.06708515e+06,  -9.26396848e+06,\n",
       "         2.40364346e+06,   1.91349466e+07,  -3.92581263e+04,\n",
       "        -2.08158551e+03,  -1.95989556e+03,   1.18240520e+03,\n",
       "         1.90728177e+05,   1.27598129e+05,  -1.76945187e+05,\n",
       "         6.39076537e+04,  -5.14174441e+05,  -1.78387998e+06,\n",
       "        -1.20186399e+03])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Test on all dataset\n",
    "beta = np.zeros(data_hat.shape[1], dtype=float)\n",
    "beta = my_train(data_hat, target, 100, beta)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test  on a small data set A\n",
    "A = np.array([[1,0], [0, 1]])\n",
    "A_hat = np.append(A, np.ones([A.shape[0], 1]), 1)\n",
    "A_y = np.array([[0], [1]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A_beta = np.array([[0], [1], [1]], dtype=float)\n",
    "iter = 100\n",
    "for i in range(iter):\n",
    "    A_beta -= trans(grad(A_hat, A_beta, A_y)) / hessian(A_hat, A_beta, A_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
